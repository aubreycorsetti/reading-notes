# Day 10 Notes

## Linear Regressions

### How to run Linear Regression in Python

> Think of Linear regression as finding the straight line that best fits a set of scattered data points

### Key Concepts

â€¢ Best Fit- the straight line in a plot that minimizes the deviation between related scattered data points.

â€¢ Coefficient â€“ also known as a parameter, is the factor a variable is multiplied by. In linear regression, a coefficient represents changes in a Response Variable.

â€¢ Coefficient of Determination â€“ the correlation coefficient denoted as ð‘…Â². Used to describe the precision or degree of fit in a regression.

â€¢ Correlation â€“ the relationship between two variables in terms of quantifiable strength and degree, often referred to as the â€˜degree of correlationâ€™.  Values range between -1.0 and 1.0.

â€¢ Dependent Feature â€“ a variable denoted as y in the slope equation y=ax+b. Also known as an Output, or a Response.

â€¢ Estimated Regression Line â€“ the straight line that best fits a set of scattered data points.
Independent Feature â€“ a variable denoted as x in the slope equation y=ax+b. Also known as an Input, or a predictor.

â€¢ Intercept â€“ the location where the Slope intercepts the Y-axis denoted b in the slope equation y=ax+b.

â€¢ Least Squares â€“ a method of estimating a Best Fit to data, by minimizing the sum of the squares of the differences between observed and estimated values.

â€¢ Mean â€“ an average of a set of numbers, but in linear regression, Mean is modeled by a linear function.

â€¢Ordinary Least Squares Regression (OLS) â€“ more commonly known as Linear Regression.

â€¢ Residual â€“ vertical distance between a data point and the line of regression.

â€¢ Regression â€“ estimate of predictive change in a variable in relation to changes in other variables.

â€¢ Regression Model â€“ the ideal formula for approximating a regression.

â€¢ Response Variables â€“ includes both the Predicted Response (the value predicted by the regression) and the Actual Response, which is the actual value of the data point.

â€¢ Slope â€“ the steepness of a line of regression. Slope and Intercept can be used to define the linear relationship between two variables: y=ax+b.

â€¢ Simple Linear Regression â€“ a linear regression that has a single independent variable.

> Regression vs Classification: The main difference between regression and classification is that the output variable in regression is continuous, while the output for classification is discrete. Regression predicts quantity; classification predicts labels.

#### Things I want to know more about

I would like to know how to wrap my head around this... I'm not good at math.

#### Source

https://www.activestate.com/resources/quick-reads/how-to-run-linear-regressions-in-python-scikit-learn/

Click to return [Home!](../README.md)
